lower_p <- 1/(B+1)
upper_p <- 1 - lower_p
ps <- seq( lower_p , upper_p, length.out = B)
# step2: compute quantiles for the t-distribution with degrees of freem (df) = N-1
qs <- qt(ps,df = N-1)
qqplot(qs, tstats, xlim = range(tstats))
abline(0,1)
#ex6
set.seed(seed = 1, sample.kind = "Rounding")
N <- 1000
B <- 10000
### observed data
tstats <- replicate(B,{
X <- sample(c(-1,1),N, replace = TRUE)
sqrt(N)*mean(X) / sd(X)
})
### theory data
lower_p <- 1/(B+1)
upper_p <- 1 - lower_p
ps <- seq( lower_p , upper_p, length.out = B)
# step2: compute quantiles for the t-distribution with degrees of freem (df) = N-1
qs <- qt(ps,df = N-1)
qqplot(qs, tstats, xlim = range(tstats))
abline(0,1)
#ex7
set.seed(seed = 1, sample.kind = "Rounding")
ttestgenerator <- function(N){
X <- rnorm(n = N)
tstat <- sqrt(N)*median(X) / sd(X)
return(tstat)
}
Ns <- seq(5,55,10)
B <- 10000
mypar(3,2)
LIM <- c(-4.5,4.5)
for(N in Ns){
### simulation data observed
ts <- replicate(B,ttestgenerator(N = N))
### theory data
lower_p <- 1/(B+1)
upper_p <- 1 - lower_p
ps <- seq( lower_p , upper_p, length.out = B)
# step2: compute quantiles for the t-distribution with degrees of freem (df) = N-1
qs <- qt(ps,df = 2*N-2)
curr_plot_title <- paste("Q-Q plot with t-distribution for sample size ", N)
qqplot(qs, ts, main = curr_plot_title,
xlab = "Theoretical", ylab = "Observed",
xlim = LIM, ylim = LIM)
abline(0,1)
}
######################################################################################################################
set.seed(seed = 1, sample.kind = "Rounding")
ttestgenerator <- function(N){
X <- rnorm(n = N)
tstat <- median(X)
return(tstat)
}
Ns <- seq(5,55,10)
B <- 10000
mypar(3,2)
LIM <- c(-4.5,4.5)
for(N in Ns){
### simulation data observed
ts <- replicate(B,ttestgenerator(N = N))
curr_plot_title <- paste("Q-Q plot, normal (0,1/sqrt(N)), sample size ", N, "\nsd ", sd(ts), "1/sqrt(N) ", 1/sqrt(N))
qqnorm(ts, main = curr_plot_title,
xlab = "Theoretical", ylab = "Observed",
xlim = LIM, ylim = LIM)
qqline(ts)
}
#alternative solution
set.seed(sample.kind = "Rounding",seed = 1)
Ns <- seq(5,45,5)
library(rafalib)
mypar(3,3)
for(N in Ns){
medians <- replicate(B,ttestgenerator(N = N))
title <- paste("N=", N, " , ",
"mean=", round(x = mean(medians),digits = 2), " , ",
"sd*sqrt(N)=", round(sd(medians)*sqrt(N),digits = 2))
qqnorm(medians, main = title)
qqline(medians)
}
# week3 exercise permutations
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
filename <- basename(url)
download(url, destfile=filename)
babies <- read.table("babies.txt", header=TRUE)
bwt.nonsmoke <- filter(babies, smoke==0) %>% select(bwt) %>% unlist()
bwt.smoke <- filter(babies, smoke==1) %>% select(bwt) %>% unlist()
N <- 10
set.seed(seed = 1, sample.kind = "Rounding")
nonsmokers <- sample(bwt.nonsmoke , N)
smokers <- sample(bwt.smoke , N)
obs <- mean(smokers) - mean(nonsmokers)
### perform perturbation test (this will make the null distribution/hypothesis true)
### concatenate data, permute/shuffle, and draw 2 samples of equal size N
dat <- c(nonsmokers,smokers)
shuffle <- sample(dat)
nonsmokerstar <- shuffle[ 1 : N ]
smokerstar <- shuffle[ (N+1) : (2*N) ]
mean(smokerstar) - mean(nonsmokerstar)
#ex1
#step1
set.seed(1,sample.kind = "Rounding")
nonsmokers <- sample(bwt.nonsmoke , N)
smokers <- sample(bwt.smoke , N)
obs <- mean(smokers) - mean(nonsmokers)
#step2
set.seed(1,sample.kind = "Rounding")
dat <- c(smokers,nonsmokers)
shuffle <- sample( dat )
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
mean(smokersstar)-mean(nonsmokersstar)
#step3
B <- 1000
### define function to generate a single observation from the null dist.
null <- function(N){
shuffle <- sample( dat )
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
mean(smokersstar)-mean(nonsmokersstar)
}
set.seed(1,sample.kind = "Rounding")
nulls <- replicate(1000, null(N))
## we add 1 to avoid p-value of 0
cnt_more_extreme_than_obs <- (sum( abs(nulls) >= abs(obs)) + 1 )
cnt_total <- length(nulls) + 1
p_val <- cnt_more_extreme_than_obs/cnt_total
p_val
#ex2
#step1
set.seed(1,sample.kind = "Rounding")
nonsmokers <- sample(bwt.nonsmoke , N)
smokers <- sample(bwt.smoke , N)
obs <- median(smokers) - median(nonsmokers)
#step2
set.seed(1,sample.kind = "Rounding")
dat <- c(smokers,nonsmokers)
shuffle <- sample( dat )
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
median(smokersstar)-median(nonsmokersstar)
#step3
B <- 1000
### define function to generate a single observation from the null dist.
null <- function(N){
shuffle <- sample( dat )
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
median(smokersstar)-median(nonsmokersstar)
}
set.seed(1,sample.kind = "Rounding")
nulls <- replicate(1000, null(N))
## as before we add 1 to avoid p-value of 0
cnt_more_extreme_than_obs <- (sum( abs(nulls) >= abs(obs)) + 1 )
cnt_total <- length(nulls) + 1
p_val <- cnt_more_extreme_than_obs/cnt_total
p_val
# Set the seed for reproducibility
set.seed(1)
# Number of permutations
num_permutations <- 1000
# Observed difference
obs <- mean(smokers) - mean(nonsmokers)
# Create a null distribution through permutation
permuted_differences <- replicate(num_permutations, {
dat <- c(smokers, nonsmokers)
shuffle <- sample(dat)
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
return(mean(smokersstar) - mean(nonsmokersstar))
})
# Calculate the permutation-derived p-value
p_value_permutation <- mean(abs(permuted_differences) >= abs(obs))
# Print the permutation-derived p-value
cat("Permutation-derived p-value:", p_value_permutation, "\n")
## as before we add 1 to avoid p-value of 0
cnt_more_extreme_than_obs <- (sum( abs(nulls) >= abs(obs)) + 1 )
p_val# week3 exercise permutations
# week3 exercise permutations
library(downloader)
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
filename <- basename(url)
download(url, destfile=filename)
babies <- read.table("babies.txt", header=TRUE)
bwt.nonsmoke <- filter(babies, smoke==0) %>% select(bwt) %>% unlist()
bwt.smoke <- filter(babies, smoke==1) %>% select(bwt) %>% unlist()
N <- 10
set.seed(seed = 1, sample.kind = "Rounding")
nonsmokers <- sample(bwt.nonsmoke , N)
smokers <- sample(bwt.smoke , N)
obs <- mean(smokers) - mean(nonsmokers)
### perform perturbation test (this will make the null distribution/hypothesis true)
### concatenate data, permute/shuffle, and draw 2 samples of equal size N
dat <- c(nonsmokers,smokers)
shuffle <- sample(dat)
nonsmokerstar <- shuffle[ 1 : N ]
smokerstar <- shuffle[ (N+1) : (2*N) ]
mean(smokerstar) - mean(nonsmokerstar)
#ex1
#step1
set.seed(1,sample.kind = "Rounding")
nonsmokers <- sample(bwt.nonsmoke , N)
smokers <- sample(bwt.smoke , N)
obs <- mean(smokers) - mean(nonsmokers)
#step2
set.seed(1,sample.kind = "Rounding")
dat <- c(smokers,nonsmokers)
shuffle <- sample( dat )
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
mean(smokersstar)-mean(nonsmokersstar)
#step3
B <- 1000
### define function to generate a single observation from the null dist.
null <- function(N){
shuffle <- sample( dat )
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
mean(smokersstar)-mean(nonsmokersstar)
}
set.seed(1,sample.kind = "Rounding")
nulls <- replicate(1000, null(N))
## we add 1 to avoid p-value of 0
cnt_more_extreme_than_obs <- (sum( abs(nulls) >= abs(obs)) + 1 )
cnt_total <- length(nulls) + 1
p_val <- cnt_more_extreme_than_obs/cnt_total
p_val
#ex2
#step1
set.seed(1,sample.kind = "Rounding")
nonsmokers <- sample(bwt.nonsmoke , N)
smokers <- sample(bwt.smoke , N)
obs <- median(smokers) - median(nonsmokers)
#step2
set.seed(1,sample.kind = "Rounding")
dat <- c(smokers,nonsmokers)
shuffle <- sample( dat )
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
median(smokersstar)-median(nonsmokersstar)
#step3
B <- 1000
### define function to generate a single observation from the null dist.
null <- function(N){
shuffle <- sample( dat )
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
median(smokersstar)-median(nonsmokersstar)
}
set.seed(1,sample.kind = "Rounding")
nulls <- replicate(1000, null(N))
## as before we add 1 to avoid p-value of 0
cnt_more_extreme_than_obs <- (sum( abs(nulls) >= abs(obs)) + 1 )
cnt_total <- length(nulls) + 1
p_val <- cnt_more_extreme_than_obs/cnt_total
p_val
# Set the seed for reproducibility
set.seed(1)
# Number of permutations
num_permutations <- 1000
# Observed difference in median
obs <- median(smokers) - median(nonsmokers)
# Create a null distribution through permutation for differences in median
permuted_differences <- replicate(num_permutations, {
dat <- c(smokers, nonsmokers)
shuffle <- sample(dat)
smokersstar <- shuffle[1:N]
nonsmokersstar <- shuffle[(N+1):(2*N)]
return(median(smokersstar) - median(nonsmokersstar))
})
# Calculate the permutation-derived p-value for differences in median
p_value_permutation <- mean(abs(permuted_differences) >= abs(obs))
# Print the permutation-derived p-value for differences in median
cat("Permutation-derived p-value for differences in median:", p_value_permutation, "\n")
# week 3 exercise association tests
d = read.csv("assoctest.csv")
#ex1
tab <- table(d$allele, d$case)
chi_sq_test <- chisq.test(tab)
X_sq <- chi_sq_test$statistic
X_sq
#ex2
fisher_test <- fisher.test(tab)
p_val <- fisher_test$p.value
p_val
#### week 4 exercise scatterplot
data(nym.2002, package="UsingR")
library(dplyr)
#ex1
# pearson correlation btw. age & time-to-finish
males <- filter(nym.2002, gender == "Male")
females <- filter(nym.2002, gender == "Female")
males_age <- males$age
males_time <- males$time
cor_age_time <- cor(x = males_age , y = males_time  , method = "pearson")
cat(sprintf("The correlation between age and time for male is %.2f.\n", cor_age_time))
#ex2
females_age <- females$age
females_time <- females$time
female_cor_age_time <- cor(x = females_age , y = females_time  , method = "pearson")
cat(sprintf("The correlation between age and time for female is %.3f.\n", female_cor_age_time))
#ex3
hist_breaks <- seq(5,85,5)
label_breaks <- c("5-10",
"10-15",
"15-20",
"20-25",
"25-30",
"30-35",
"35-40",
"40-45",
"45-50",
"50-55",
"55-60",
"60-65",
"65-70",
"70-75",
"75-80",
"80-85")
nym.2002$age.cat <- cut(nym.2002$age, breaks = hist_breaks, labels = label_breaks)
mypar(3,1)
times <- nym.2002$time
ages <- nym.2002$age.cat
#boxplot(split(values,factor))
boxplot(times ~ ages)
# scatterplot no.1
avg_times <- tapply(times, ages, mean)
avg_times <- avg_times[-(1:2)]
valid_ages <- seq(20,85,5)
# age_groups without NaNs :
# 15-20" "20-25" "25-30" "30-35" "35-40" "40-45" "45-50" "50-55" "55-60" "60-65" "65-70" "70-75" "75-80" "80-85
plot(valid_ages,avg_times)
# scatterplot no.2
plot(nym.2002$age,nym.2002$time)
### alternative solution (by gender)
library(rafalib)
mypar(2,2)
plot(females$age, females$time)
plot(males$age, males$time)
group <- floor(females$age/5) * 5
boxplot(females$time~group)
group <- floor(males$age/5) * 5
boxplot(males$time~group)
### week 4 symmetry of log ratios exercise
time = sort(nym.2002$time)
### week 4 symmetry of log ratios exercise
time = sort(nym.2002$time)
# Assuming you have loaded the 'babies' dataset and created 'nym.2002' from it
# If not, you can use the provided code to load the 'babies' dataset
# Corrected code
nym.2002 <- babies  # Assuming 'babies' is the dataset containing the necessary information
# Download and load the 'babies' dataset
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
filename <- basename(url)
download(url, destfile=filename)
babies <- read.table(filename, header=TRUE)
# Create nym.2002 from babies
nym.2002 <- babies
# Calculate necessary variables
time <- sort(nym.2002$time)
fastest_time <- time[1]
median_idx <- round(length(time)/2)
median_time <- time[median_idx]
# Exercise 1
ratio1 <- fastest_time/median_time
cat("Exercise 1 - Ratio of fastest time to median time:", ratio1, "\n")
# Exercise 2
slowest_time <- time[length(time)]
ratio2 <- slowest_time/median_time
cat("Exercise 2 - Ratio of slowest time to median time:", ratio2, "\n")
# Visualization
library(rafalib)
mypar(2, 1)
# Scatterplot of time to median time ratio
plot(time/median(time), ylim=c(1/4, 4))
# Assuming you have nym.2002 and the 'time' vector from the sorted times
# Create the vector time
time = sort(nym.2002$time)
# Download and load the 'babies' dataset
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/babies.txt"
filename <- basename(url)
download(url, destfile=filename)
babies <- read.table(filename, header=TRUE)
# Create nym.2002 from babies
nym.2002 <- babies
# Create the vector time
time <- sort(nym.2002$time)
# Calculate the fastest time divided by the median time
fastest_time <- time[1]
median_idx <- round(length(time)/2)
median_time <- time[median_idx]
# Calculate the ratio
ratio_fastest_median <- fastest_time / median_time
# Print the result
cat("The fastest time divided by the median time:", ratio_fastest_median, "\n")
### week 4 Median, MAD, and Spearman Correlation exercises
# load data of chick weights over 21 days for 4 different protein diets
data(ChickWeight)
head(ChickWeight)
plot(ChickWeight$Time, ChickWeight$weight, col=ChickWeight$Diet)
# use reshape to change view of the data from a 'long' format with repeated values for individuals in seperate rows
# to 'wide' format with all values of an individual within a single row
chick <- reshape(ChickWeight, idvar = c("Chick", "Diet"), timevar = "Time", direction = "wide")
head(chick)
# remove any row that has a missing observation "NA"
chick <- na.omit(chick)
#ex0
weights_day4 <- chick[,"weight.4"]
weights_day4_with_outlier <- c(weights_day4,3000)
avg_day4 <- mean(weights_day4)
avg_day4_with_outlier <- mean(weights_day4_with_outlier)
cat(sprintf("mean of data without outlier measurement %.2f",avg_day4))
cat(sprintf("mean of data with outlier measurement %.2f",avg_day4_with_outlier))
ratio1 <- avg_day4_with_outlier/avg_day4
ratio1
#ex1
weights_day4 <- chick[,"weight.4"]
weights_day4_with_outlier <- c(weights_day4,3000)
avg_day4 <- mean(weights_day4)
avg_day4_with_outlier <- mean(weights_day4_with_outlier)
cat(sprintf("\nmean of data without outlier measurement %.2f \n",avg_day4))
cat(sprintf("\nmean of data with outlier measurement %.2f \n",avg_day4_with_outlier))
mean_ratio <- avg_day4_with_outlier/avg_day4
mean_ratio
#ex2
median_day4 <- median(weights_day4)
median_day4_with_outlier <- median(weights_day4_with_outlier)
cat(sprintf("\nmedian of data without outlier measurement %.2f \n",median_day4))
cat(sprintf("\nmedian of data with outlier measurement %.2f \n",median_day4_with_outlier))
median_ratio <- median_day4_with_outlier/median_day4
median_ratio
#ex3
sd_day4 <- sd(weights_day4)
sd_day4_with_outlier <- sd(weights_day4_with_outlier)
cat(sprintf("\nstandard deviation of data without outlier measurement %.2f \n",sd_day4))
cat(sprintf("\nstandard deviation of data with outlier measurement %.2f \n",sd_day4_with_outlier))
sd_ratio <- sd_day4_with_outlier/sd_day4
sd_ratio
#ex4
mad_day4 <- mad(weights_day4)
mad_day4_with_outlier <- mad(weights_day4_with_outlier)
cat(sprintf("\nmean absolute deviation of data without outlier measurement %.2f \n",mad_day4))
cat(sprintf("\nmean absolute deviation of data with outlier measurement %.2f \n",mad_day4_with_outlier))
mad_ratio <- mad_day4_with_outlier/mad_day4
mad_ratio
#ex5
weights_day4 <- chick[,"weight.4"]
weights_day21 <- chick[,"weight.21"]
plot(weights_day4,weights_day21)
weights_day4_with_outlier <- c(weights_day4,3000)
weights_day21_with_outlier <- c(weights_day21,3000)
corr <- cor(weights_day4,weights_day21)
corr_with_outlier <- cor(weights_day4_with_outlier,weights_day21_with_outlier)
corr_ratio <- corr_with_outlier/corr
corr_ratio
### week 4 Mann-Whitney-Wilcoxon Test exercises
# load data of chick weights over 21 days for 4 different protein diets
data(ChickWeight)
head(ChickWeight)
plot(ChickWeight$Time, ChickWeight$weight, col=ChickWeight$Diet)
# use reshape to change view of the data from a 'long' format with repeated values for individuals in seperate rows
# to 'wide' format with all values of an individual within a single row
chick <- reshape(ChickWeight, idvar = c("Chick", "Diet"), timevar = "Time", direction = "wide")
head(chick)
# remove any row that has a missing observation "NA"
chick <- na.omit(chick)
#ex1
# day 4 weights diet 1
x <- filter(chick, Diet == 1) %>% select("weight.4") %>% unlist()
# day 4 weights diet 4
y <- filter(chick, Diet == 4) %>% select("weight.4") %>% unlist()
# alternatively acess data with
# x <- chick$weight.4[chick$Diet == 1]
# x <- chick$weight.4[chick$Diet == 1]
# t-test
ttest <- t.test(x,y)
# wilcox test
wtest <- wilcox.test(x,y)
# add outlier
x_with_outlier <- c(x,200)
ttest_pval_outlier <- t.test(x_with_outlier,y)$p.value
ttest_pval_outlier
#ex2
wtest_pval_outlier <- wilcox.test(x_with_outlier,y)$p.value
wtest_pval_outlier
#ex3
library(rafalib)
mypar(1,3)
boxplot(x,y)
boxplot(x,y+10)
boxplot(x,y+100)
ttest1 <- t.test(x,y+10)$statistic
ttest2 <- t.test(x,y+100)$statistic
diff_ttests <- ttest1 - ttest2
diff_ttests
wtest1 <- wilcox.test(x,y+10)$statistic
wtest2 <- wilcox.test(x,y+100)$statistic
diff_wtests <- wtest1 - wtest2
diff_wtests
#ex4
v1 <- c(1,2,3)
v2 <- c(14,5,6)
wtest_pval1 <- wilcox.test(v1,v2)$p.value
wtest_pval1
#ex5
v3 <-  100*v2
wtest_pval2 <- wilcox.test(v1,v3)$p.value
wtest_pval2
